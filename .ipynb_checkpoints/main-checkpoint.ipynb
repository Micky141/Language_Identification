{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some special characters\n",
    "def remove_special_chars(sen, filter_chars):\n",
    "    sen = sen.strip()\n",
    "    sen = sen.lower()\n",
    "    for each in sen:\n",
    "        num_ascii = ord(each)\n",
    "        # delete number, \".\", \"\\\", all chars in filter_chars\n",
    "        if (num_ascii > 47 and num_ascii < 58) or num_ascii == 92 or num_ascii == 46 or (each in filter_chars):\n",
    "            sen = sen.replace(each, \"\")\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file csv and convert it to pandasframe\n",
    "def open_file(name):\n",
    "    with open('database/{file_name}.csv'.format(file_name = \"formatted_data\")) as f:\n",
    "        content = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "\n",
    "    data = []\n",
    "    for num, each in enumerate(content):\n",
    "        each = each.split(\";\")\n",
    "\n",
    "        if \".\" in each[1]:\n",
    "            sentences = each[1].split(\".\") \n",
    "            filter_chars = ['\\t', '!', '\"', '%', '&', '*', '+', ',', '-', '/', ':', '=', '?', '@', '[', ']', '§', \n",
    "                            '«', \"”\", \"\\\\\", \".\", '»']\n",
    "                    \n",
    "            for number, sen in enumerate(sentences):\n",
    "                \"\"\"\n",
    "                insert remove special characters\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                # filter no meaning words\n",
    "                sen = remove_special_chars(sen, filter_chars)\n",
    "\n",
    "                # make sure a sentence have len(sentence) > 0\n",
    "                if len(sen)>0:\n",
    "                    data.append([each[0], sen, each[2]])\n",
    "\n",
    "        else:\n",
    "            data.append(each)\n",
    "\n",
    "    main_data = data[1:]\n",
    "    main_data = shuffle(main_data)\n",
    "    df = pd.DataFrame(main_data, columns = data[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_file('formatted_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78160, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>et</td>\n",
       "      <td>istungi algusse abre la sesión a las</td>\n",
       "      <td>324119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cs</td>\n",
       "      <td>zasedání skončilo v schválení zápisu z předcho...</td>\n",
       "      <td>317927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>da</td>\n",
       "      <td>jeg glemmer bestemt ikke den økonomiske side a...</td>\n",
       "      <td>678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pt</td>\n",
       "      <td>se não fixarmos uma data específica para aplic...</td>\n",
       "      <td>730576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>firstly let me make a statement of fact the fr...</td>\n",
       "      <td>690268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>pl</td>\n",
       "      <td>horaszatwierdzenie protokołu z poprzedniego p...</td>\n",
       "      <td>317026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>es</td>\n",
       "      <td>las detenciones las torturas las violaciones d...</td>\n",
       "      <td>733658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>en</td>\n",
       "      <td>we are also currently examining how we can mos...</td>\n",
       "      <td>690268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "      <td>we cannot continue with a situation where inco...</td>\n",
       "      <td>690268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>el</td>\n",
       "      <td>επίτροπο να εργασθεί και στα οποία του ζητώ να...</td>\n",
       "      <td>523277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                               text length_text\n",
       "0       et              istungi algusse abre la sesión a las       324119\n",
       "1       cs  zasedání skončilo v schválení zápisu z předcho...      317927\n",
       "2       da  jeg glemmer bestemt ikke den økonomiske side a...      678400\n",
       "3       pt  se não fixarmos uma data específica para aplic...      730576\n",
       "4       en  firstly let me make a statement of fact the fr...      690268\n",
       "5       pl   horaszatwierdzenie protokołu z poprzedniego p...      317026\n",
       "6       es  las detenciones las torturas las violaciones d...      733658\n",
       "7       en  we are also currently examining how we can mos...      690268\n",
       "8       en  we cannot continue with a situation where inco...      690268\n",
       "9       el  επίτροπο να εργασθεί και στα οποία του ζητώ να...      523277"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da\n",
      "effekten af projekter der er gennemført ved hjælp af unionsstøtte svækkes ofte ved en langsom beslutningstagning og kompliceret forvaltning\n"
     ]
    }
   ],
   "source": [
    "# get data in a row\n",
    "def get_data(df = df, row = 60000):\n",
    "    return  df.iloc[row][0], df.iloc[row][1]\n",
    "\n",
    "label, text = get_data(row = 700)\n",
    "print(label)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize sentences and split it in to train and test file\n",
    "def vectorization(df, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(df[\"text\"]), list(df[\"language\"]), test_size=test_size, random_state=42)\n",
    "\n",
    "    # vectorize sentence X\n",
    "    count_vectorizer = CountVectorizer(analyzer='char')\n",
    "    X_train_features = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_features = count_vectorizer.transform(X_test)\n",
    "\n",
    "    # vectorize label Y\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    y_train_features = label_encoder.fit_transform(y_train)\n",
    "    y_test_features = label_encoder.transform(y_test)\n",
    "    \n",
    "    # getted features\n",
    "    features = count_vectorizer.get_feature_names()\n",
    "    \n",
    "    # getted labels\n",
    "    labels = list(label_encoder.classes_)\n",
    "    \n",
    "    return X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer\n",
    "\n",
    "X_train_features, y_train_features, X_test_features, y_test_features, features, labels, count_vectorizer = vectorization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '\\xad', '·', 'º', '¿', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ā', 'ă', 'ą', 'ć', 'č', 'ď', 'ē', 'ė', 'ę', 'ě', 'ģ', 'ī', 'į', 'ķ', 'ĺ', 'ļ', 'ľ', 'ł', 'ń', 'ņ', 'ň', 'ő', 'ŕ', 'ř', 'ś', 'ş', 'š', 'ţ', 'ť', 'ū', 'ů', 'ű', 'ų', 'ź', 'ż', 'ž', 'ș', 'ț', 'ΐ', 'ά', 'έ', 'ή', 'ί', 'α', 'β', 'γ', 'δ', 'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω', 'ϊ', 'ϋ', 'ό', 'ύ', 'ώ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ь', 'ю', 'я', 'і', 'љ', 'ћ', '№']\n",
      "\n",
      "Len features:  168\n"
     ]
    }
   ],
   "source": [
    "# number of the features\n",
    "print(\"features: \", features)\n",
    "print(\"\\nLen features: \", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 1, 4, 2, 9, 0, 3, 2, 7, 1, 5, 1, 2, 3, 8, 3, 0, 3, 6, 3, 0,\n",
       "       0, 7, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9273751238636891\n"
     ]
    }
   ],
   "source": [
    "# create and training model MultinomialNB\n",
    "modelNB = MultinomialNB()\n",
    "modelNB.fit(X_train_features, y_train_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy: \",f1_score(y_test_features, modelNB.predict(X_test_features), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('models/modelNB.pkl', 'wb') as fid:\n",
    "    pickle.dump(modelNB, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('models/modelNB.pkl', 'rb') as fid:\n",
    "    modelNB = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  9,  3, ...,  5, 12, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict from saved model\n",
    "modelNB.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9414662231320369\n"
     ]
    }
   ],
   "source": [
    "# model Random Forest\n",
    "\n",
    "modelRF=RandomForestClassifier(n_estimators=100)\n",
    "modelRF.fit(X_train_features,y_train_features)\n",
    "\n",
    "y_pred = modelRF.predict(X_test_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('models/modelRF.pkl', 'wb') as fid:\n",
    "    pickle.dump(modelRF, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('models/modelRF.pkl', 'rb') as fid:\n",
    "    modelRF = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  9,  3, ...,  5, 12, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict from saved model\n",
    "modelRF.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### optimize parametters for random forest model, accuracy can be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal paras:  {'max_features': 'log2', 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# tuning model by grid search cv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(), n_jobs = -1, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_features, y_train_features)\n",
    "\n",
    "# choose the best parametters \n",
    "print(\"Optimal paras: \", CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random forest model with the optimal parametter\n",
    "optimal_modelRF=RandomForestClassifier(n_estimators=300, max_features= 'log2')\n",
    "\n",
    "#Train the model using the training sets \n",
    "optimal_modelRF.fit(X_train_features,y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9465839303991812\n"
     ]
    }
   ],
   "source": [
    "# find the accuracy\n",
    "y_pred = optimal_modelRF.predict(X_test_features)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_features, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('models/optimal_modelRF.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid) \n",
    "    \n",
    "# load it again\n",
    "with open('models/optimal_modelRF.pkl', 'rb') as fid:\n",
    "    optimal_modelRF = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model support vector machine - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 665    3    0    2    0    0    1    0    0    1    0    0    0    1\n",
      "     0    0    0   13    0    0    0]\n",
      " [   7  478    1    3    0    2    7    0    0    1    1    0    2    1\n",
      "     1    0    0    1   16    3    0]\n",
      " [   0    0 1038    0    0    2    0    0    0    1    0    0    0    4\n",
      "     7    0    0    0    0    2    8]\n",
      " [   2    1   16  890    0    8    2    1    0    0    1    0    4    7\n",
      "    12    1    0    2    3    1    1]\n",
      " [   2    0    1    1  590    0    0    0    0    0    0    0    2    0\n",
      "     0    0    0    1    0    0    0]\n",
      " [   1    1   10   10    0  862    4    0    0    2    1    3    5    4\n",
      "     7    0    0    1    3    0    0]\n",
      " [   1    1    2    0    0   11  878    0    0   12    1    9    5    3\n",
      "     0    1   25    0    6    0    0]\n",
      " [   6    2    4    4    0    0    3  481   10    2    0    0    5    2\n",
      "     1    0    0    5    0    1    4]\n",
      " [   0    0    1    1    0    0    0   14  867    0    0    0    1    0\n",
      "     0    0    0    0    2    1    0]\n",
      " [   2    0    4    1    0    1   16    1    0  877    1    9    3    1\n",
      "     2    0    1    1    2    0    2]\n",
      " [   3    6    3    1    0    2    3    1    0    0  475    0    0    1\n",
      "     0    1    1    5    2    2    1]\n",
      " [   0    0    0    0    0    3   17    3    0    2    0  804    1    0\n",
      "     1    0    2    4    1    0    0]\n",
      " [   4    2    2    2    0    3    6    2    1    1    1    2  667    3\n",
      "     0    1    0    4    0    3    1]\n",
      " [   9    0    6    1    1    0    8    2    1    5    0    0    6  711\n",
      "     0    0    0    5    0    4    0]\n",
      " [   0    0   19   15    0    8    3    0    0    2    2    2    2    4\n",
      "   940    1    0    2    2    5    0]\n",
      " [   4    2    0    3    1    3    7    1    0    0    1    0    3    1\n",
      "     2  429    0    5    0    0    1]\n",
      " [   0    0    0    0    0    0   35    2    0   12    0    5    1    0\n",
      "     0    0  788    2    1    1    0]\n",
      " [  12    1    1    4    0    2    3    1    0    8    0    5    1    4\n",
      "     1    0    1  449    0    0    0]\n",
      " [   9   10    0    0    0    1   11    0    0    1    2    0    3    2\n",
      "     2    1    2    6  450    4    0]\n",
      " [   7    2    2    1    0    1    4    2    0    0    0    0    5    2\n",
      "     5    2    0    6    4  526    0]\n",
      " [   0    0   20    5    0    1    1    1    0    1    0    1    1    4\n",
      "     3    0    0    0    0    0  871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       686\n",
      "           1       0.94      0.91      0.93       524\n",
      "           2       0.92      0.98      0.95      1062\n",
      "           3       0.94      0.93      0.94       952\n",
      "           4       1.00      0.99      0.99       597\n",
      "           5       0.95      0.94      0.95       914\n",
      "           6       0.87      0.92      0.89       955\n",
      "           7       0.94      0.91      0.92       530\n",
      "           8       0.99      0.98      0.98       887\n",
      "           9       0.95      0.95      0.95       924\n",
      "          10       0.98      0.94      0.96       507\n",
      "          11       0.96      0.96      0.96       838\n",
      "          12       0.93      0.95      0.94       705\n",
      "          13       0.94      0.94      0.94       759\n",
      "          14       0.96      0.93      0.94      1007\n",
      "          15       0.98      0.93      0.95       463\n",
      "          16       0.96      0.93      0.95       847\n",
      "          17       0.88      0.91      0.89       493\n",
      "          18       0.91      0.89      0.90       504\n",
      "          19       0.95      0.92      0.94       569\n",
      "          20       0.98      0.96      0.97       909\n",
      "\n",
      "    accuracy                           0.94     15632\n",
      "   macro avg       0.94      0.94      0.94     15632\n",
      "weighted avg       0.94      0.94      0.94     15632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SVM = SVC(kernel='linear')\n",
    "model_SVM.fit(X_train_features, y_train_features)\n",
    "\n",
    "y_pred = model_SVM.predict(X_test_features)\n",
    "\n",
    "print(confusion_matrix(y_test_features,y_pred))\n",
    "print(classification_report(y_test_features,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = list(df[\"text\"]), list(df[\"language\"])\n",
    "\n",
    "# vectorize sentence X\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "X_features = count_vectorizer.fit_transform(X)\n",
    "\n",
    "# vectorize label Y\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "Y_features = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To save time, We will find the best model from just 4 classifying algorithms RF, SVC, GaussianNB, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    SVC(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  5,  1, ...,  0,  0,  0],\n",
       "       [62, 20,  1, ...,  0,  0,  0],\n",
       "       [20,  5,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [35, 20,  3, ...,  0,  0,  0],\n",
       "       [32, 17,  1, ...,  0,  0,  0],\n",
       "       [35, 20,  1, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  1,  2, ...,  6,  6, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78160"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94079284 0.9434638  0.9470957  0.9484226  0.937408  ]\n",
      "[0.91432225 0.91385265 0.91613357 0.92116209 0.913344  ]\n",
      "[0.81675192 0.82693784 0.82970829 0.81928713 0.81888   ]\n",
      "[0.93842711 0.93789972 0.9392912  0.94176745 0.930752  ]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, \n",
    "                                 X_features.toarray(), \n",
    "                                 Y_features, \n",
    "                                 scoring='accuracy', \n",
    "                                 cv=CV, \n",
    "                                 n_jobs=-1                                \n",
    "                                 )\n",
    "    print(accuracies)    \n",
    "    entries.append([model_name, sum(accuracies)/len(accuracies)])\n",
    "\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.943437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.915763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.822313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.937627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name  accuracy\n",
       "0  RandomForestClassifier  0.943437\n",
       "1                     SVC  0.915763\n",
       "2              GaussianNB  0.822313\n",
       "3      LogisticRegression  0.937627"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "def test(test):\n",
    "    test = [test]\n",
    "    test_feature = count_vectorizer.transform(test)\n",
    "    test_feature.shape\n",
    "    \n",
    "    global labels\n",
    "    for num, each in enumerate(labels):\n",
    "        if num == modelRF.predict(test_feature)[0]:\n",
    "            return each\n",
    "\n",
    "test('hello, my name is Giang, I come from Vietnam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
